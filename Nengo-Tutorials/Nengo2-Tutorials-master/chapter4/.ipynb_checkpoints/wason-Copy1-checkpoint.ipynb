{
 "metadata": {
  "name": "",
  "signature": "sha256:b070507b4cc690c1b40fbcc9393bef25543743632e5906183c5c8a127c0b2b8e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Structured Representations\n",
      "\n",
      "This demo shows a method for constructing structured representations using semantic pointers. It uses a convolution network to bind two Semantic Pointers and a Sum network to cojoin to semantic pointers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from nengo.dists import Uniform\n",
      "%matplotlib inline\n",
      "\n",
      "import nengo\n",
      "from nengo.spa import Vocabulary\n",
      "\n",
      "# Change the seed of this RNG to change the vocabulary\n",
      "rng = np.random.RandomState(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D=6   #128   # number of dimensions per ensemble\n",
      "N=20    # number of neurons per ensemble is N*D\n",
      "experiment=2   # 1 for learning in different contexts, 2 for generalization within a context\n",
      "learning_rate=5e-7\n",
      "stimulus_time=1.5\n",
      "\n",
      "mode_other=nengo.LIF() # mode to use for all neurons that aren't part of the learning system (or part of convolution)\n",
      "mode_conv=nengo.LIF() # mode to use for the convolution computation\n",
      "# Set both mode parameters to 'default' to use spiking neurons for everything.  The resulting\n",
      "#  model will run quite slowly....\n",
      "\n",
      "import random\n",
      "#import nef\n",
      "#import hrr\n",
      "\n",
      "\n",
      "# number of neurons to use for other neural groups\n",
      "N_other= N*D\n",
      "if mode_other==nengo.LIF(): N_other=1\n",
      "\n",
      "# number of neurons to use for convolution subcomponents\n",
      "N_conv=20 #300\n",
      "if mode_conv==nengo.LIF(): N_conv=1\n",
      "\n",
      "    \n",
      "vocab = Vocabulary(dimensions=D, rng=rng, max_similarity=0.1)\n",
      "    \n",
      "model = nengo.Network(label='Wason', seed=16)\n",
      "with model:  \n",
      "    context = nengo.Ensemble(label='context', n_neurons=N, dimensions=1, intercepts=Uniform(0.2,0.9))\n",
      "    rule = nengo.Ensemble(label='rule', n_neurons=N_other, dimensions=D, neuron_type=mode_other)\n",
      "    transform = nengo.Ensemble(label='transform', n_neurons=N_other, dimensions=D)\n",
      "    answer = nengo.Ensemble(label='answer', n_neurons=N_other, dimensions=D, neuron_type=nengo.LIF()) # SS nengo.Direct())\n",
      "   \n",
      "    # computing  T convolved with R\n",
      "    cconv = nengo.networks.CircularConvolution(n_neurons=D*N_conv, dimensions=D)\n",
      "    nengo.Connection(rule, cconv.A)\n",
      "    nengo.Connection(transform, cconv.B)\n",
      "    nengo.Connection(cconv.output, answer)\n",
      "\n",
      "    \"\"\" SS I don't know what 'mode' maps to\n",
      "    nef.convolution.make_convolution(net,'*',rule,transform,answer,N_conv,mode=mode_conv)\"\"\"\n",
      "    \n",
      "    correct_transform = nengo.Ensemble(label='correct transform', n_neurons=N_other, dimensions=D, neuron_type=mode_other)\n",
      "    correct_answer = nengo.Ensemble(label='correct answer', n_neurons=N_other, dimensions=D, neuron_type=mode_other)\n",
      "\n",
      "    # computing R' convolved with A* (correct answer)\n",
      "    cconv2 = nengo.networks.CircularConvolution(n_neurons=D*N_conv, dimensions=D, invert_b=True)\n",
      "    nengo.Connection(correct_answer, cconv.A)\n",
      "    nengo.Connection(rule, cconv.B)\n",
      "    nengo.Connection(cconv.output, correct_transform)\n",
      "    \n",
      "    \n",
      "    conn = nengo.Connection(context, transform, function=lambda x: np.random.random(D))\n",
      "    error = nengo.Ensemble(N_other, dimensions=D)\n",
      "    \n",
      "    # Error = pre - post\n",
      "    #nengo.Connection(context, error)\n",
      "    nengo.Connection(transform, error, transform=-1)\n",
      "    nengo.Connection(correct_transform, error)\n",
      "    \n",
      "    # Modulatory connections don't impart current\n",
      "    error_conn = nengo.Connection(error, transform, modulatory=True)\n",
      "    # Add the learning rule to the connection\n",
      "    conn.learning_rule_type = nengo.PES(error_conn)\n",
      "    \n",
      "    # -- inhibit error after 3 seconds\n",
      "    inhib = nengo.Node(lambda t: 2.0 if t > 3.0 else 0.0)\n",
      "    nengo.Connection(inhib, error.neurons, transform=[[-1]] * error.n_neurons)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import random\n",
      "#random.seed(99)  #seed for vocabulary items\n",
      "\n",
      "# Put possible answers in the vocabulary \n",
      "# our ground-truth to test the accuracy of the neural network.\n",
      " \n",
      "\n",
      "if experiment==1:\n",
      "    \n",
      "    vocab.add('ANSWER1', vocab.parse('VOWEL+EVEN'))    \n",
      "    vocab.add('ANSWER2', vocab.parse('DRINK+NOT*OVER18')) \n",
      "\n",
      "    RULE1=vocab.parse('ANTE*VOWEL+CONS*EVEN')\n",
      "    RULE2=vocab.parse('ANTE*DRINK+CONS*OVER18')\n",
      "    ANSWER1=vocab.parse('VOWEL+EVEN')\n",
      "    ANSWER2=vocab.parse('DRINK+NOT*OVER18')\n",
      "    vocab.add('NOT_OVER18',vocab.parse('NOT*OVER18'))\n",
      "    ANSWER1.normalize()\n",
      "    ANSWER2.normalize()\n",
      "    RULE1.normalize()\n",
      "    RULE2.normalize()\n",
      "\n",
      "    with model:\n",
      "        abstract_context = nengo.Node(output=lambda t: -1 if t <= 1.5 or (t>3.0 and t<=4.5) else 0.0, size_out=1)\n",
      "        familiar_context = nengo.Node(output=lambda t: 1 if (t>1.5 and t<=3.0) or (t>4.5 and t<=6) else 0.0, size_out=1)\n",
      "        rule1 = nengo.Node(output=lambda t: RULE1.v if t <= 1.5 or (t>3.0 and t<=4.5) else 0.0, size_out=D)\n",
      "        rule2 = nengo.Node(output=lambda t: RULE2.v if (t>1.5 and t<=3) or (t>4.5 and t<=6) else 0.0, size_out=D)\n",
      "        answer1 = nengo.Node(output=lambda t: ANSWER1.v if t <= 1.5 else 0.0, size_out=D)\n",
      "        answer2 = nengo.Node(output=lambda t: ANSWER2.v if (t>1.5 and t<=3.0) else 0.0, size_out=D)\n",
      "\n",
      "        nengo.Connection(abstract_context, context)\n",
      "        nengo.Connection(familiar_context, context)\n",
      "        nengo.Connection(rule1, rule)\n",
      "        nengo.Connection(rule2, rule)\n",
      "        nengo.Connection(answer1, correct_answer)\n",
      "        nengo.Connection(answer2, correct_answer)\n",
      "        \n",
      "    \n",
      "\n",
      "elif experiment==2:\n",
      "    \n",
      "    vocab.add('ANSWER1', vocab.parse('DRINK+NOT*OVER21'))    \n",
      "    vocab.add('ANSWER2', vocab.parse('VOTE+NOT*OVER18')) \n",
      "    vocab.add('ANSWER3', vocab.parse('DRIVE+NOT*OVER16'))\n",
      "\n",
      "    RULE1=vocab.parse('ANTE*DRINK+CONS*OVER21')\n",
      "    RULE2=vocab.parse('ANTE*VOTE+CONS*OVER18')\n",
      "    RULE3=vocab.parse('ANTE*DRIVE+CONS*OVER16')\n",
      "\n",
      "    ANSWER1=vocab.parse('DRINK+NOT*OVER21')\n",
      "    ANSWER2=vocab.parse('VOTE+NOT*OVER18')\n",
      "    ANSWER3=vocab.parse('DRIVE+NOT*OVER16')\n",
      "    vocab.add('NOT_OVER16',vocab.parse('NOT*OVER16'))\n",
      "    vocab.add('NOT_OVER18',vocab.parse('NOT*OVER18'))\n",
      "    vocab.add('NOT_OVER21',vocab.parse('NOT*OVER21'))\n",
      "    \n",
      "    \n",
      "    ANSWER1.normalize()\n",
      "    ANSWER2.normalize()\n",
      "    ANSWER3.normalize()\n",
      "    RULE1.normalize()\n",
      "    RULE2.normalize()\n",
      "    RULE3.normalize()\n",
      "\n",
      "    with model:\n",
      "        familiar_context = nengo.Node(output=lambda t: 1 if t<6 else 0.0, size_out=1)\n",
      "        rule1 = nengo.Node(output=lambda t: RULE1.v if t <= 2 else 0.0, size_out=D)\n",
      "        rule2 = nengo.Node(output=lambda t: RULE2.v if (t>2 and t<=4) else 0.0, size_out=D)\n",
      "        rule3 = nengo.Node(output=lambda t: RULE3.v if (t>4 and t<=6) else 0.0, size_out=D)\n",
      "        answer1 = nengo.Node(output=lambda t: ANSWER1.v if t <= 2 else 0.0, size_out=D)\n",
      "        answer2 = nengo.Node(output=lambda t: ANSWER2.v if (t>2 and t<=4) else 0.0, size_out=D)\n",
      "\n",
      "        nengo.Connection(familiar_context, context)\n",
      "        nengo.Connection(rule1, rule)\n",
      "        nengo.Connection(rule2, rule)\n",
      "        nengo.Connection(rule3, rule)\n",
      "        nengo.Connection(answer1, correct_answer)\n",
      "        nengo.Connection(answer2, correct_answer)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create and run the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    # Probe the output\n",
      "    answer_probe = nengo.Probe(answer, synapse=0.1)\n",
      "    rule_probe = nengo.Probe(rule, synapse=0.1)\n",
      "    transform_probe = nengo.Probe(transform, synapse=0.1)\n",
      "    \n",
      "    correct_answer_probe = nengo.Probe(correct_answer, synapse=0.1)\n",
      "    correct_transform_probe = nengo.Probe(correct_transform, synapse=0.1)\n",
      "    \n",
      "    context_probe = nengo.Probe(context, synapse=0.1)\n",
      "    \n",
      "    error_probe = nengo.Probe(error, synapse=0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5: Run the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(6.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 6: Plot the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(14, 3))\n",
      "plt.subplot(1, 3, 1)\n",
      "plt.plot(sim.trange(), sim.data[rule_probe])\n",
      "plt.title(\"Rule\")\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "plt.plot(sim.trange(), sim.data[transform_probe])\n",
      "plt.title(\"Transform\")\n",
      "\n",
      "plt.figure(figsize=(14, 3))\n",
      "plt.subplot(1, 3, 1)\n",
      "plt.plot(sim.trange(), sim.data[answer_probe])\n",
      "plt.title(\"Answer\")\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "plt.plot(sim.trange(), sim.data[context_probe])\n",
      "plt.title(\"Context\")\n",
      "\n",
      "plt.figure(figsize=(14, 3))\n",
      "plt.subplot(1, 3, 1)\n",
      "plt.plot(sim.trange(), sim.data[correct_answer_probe])\n",
      "plt.title(\"Correct Answer\")\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "plt.plot(sim.trange(), sim.data[correct_transform_probe])\n",
      "plt.title(\"Correct Transform\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure()\n",
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[answer_probe], vocab))\n",
      "#plt.plot(sim.trange(), nengo.spa.similarity(sim.data[answer_probe], vocab, normalize=True))\n",
      "plt.xlabel(\"t [s]\")\n",
      "plt.ylabel(\"dot product\")\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analyze the results\n",
      "\n",
      "We plot the dot product between the exact convolution of `A` and `B` (given by `vocab.parse('A * B')`), and the result of the neural convolution (given by `sim.data[out]`).\n",
      "\n",
      "The dot product is a common measure of similarity between semantic pointers, since it approximates the cosine similarity when the semantic pointer lengths are close to one. The cosine similarity is a common similarity measure for vectors; it is simply the cosine of the angle between the vectors.\n",
      "\n",
      "Both the dot product and the exact cosine similarity can be computed with `nengo.spa.similarity`. Normally, this function will compute the dot products between each data vector and each vocabulary vector, but setting `normalize=True` normalizes all vectors so that the exact cosine similarity is computed instead."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[conv_probe], vocab))\n",
      "plt.legend(vocab.keys, loc=4)\n",
      "plt.xlabel(\"t [s]\")\n",
      "plt.ylabel(\"dot product\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above plot shows that the neural output is much closer to `C = A * B` than to either `A` or `B`, suggesting that our network is correctly computing the convolution. It also highlights an important property of circular convolution: The circular convolution of two vectors is dissimilar to both of the vectors.\n",
      "\n",
      "The dot product between the neural output and `C` is not exactly one due in large part to the fact that the length of `C` is not exactly one (see below). To actually measure the cosine similarity between the vectors (that is, the cosine of the angle between the vectors), we have to divide the dot product by the lengths of both `C` and the neural output vector approximating `C`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The length of `C` is not exactly one\n",
      "print(vocab['C'].length())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Performing this normalization, we can see that the cosine similarity between the neural output vectors and `C` is almost exactly one, demonstrating that the neural population is quite accurate in computing the convolution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[conv_probe], vocab, normalize=True))\n",
      "plt.legend(vocab.keys, loc=4)\n",
      "plt.xlabel(\"t [s]\")\n",
      "plt.ylabel(\"cosine similarity\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}